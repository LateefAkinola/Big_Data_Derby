{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "In this competition your task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal records recovered from the ship's damaged computer system.\n",
    "\n",
    "### File and Data Field Descriptions:\n",
    "\n",
    "    <>train.csv - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    <>PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is  their number within the group. People in a group are often family members, but not always.\n",
    "    <>HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    <>CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    <>Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    <>Destination - The planet the passenger will be debarking to.\n",
    "    <>Age - The age of the passenger.\n",
    "    <>VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    <>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    <>Name - The first and last names of the passenger.\n",
    "    <>Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "    \n",
    "test.csv - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "\n",
    "sample_submission.csv - A submission file in the correct format.\n",
    "PassengerId - Id for each passenger in the test set.\n",
    "Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# File\n",
    "import os\n",
    "\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Files\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print shape of Dataset\n",
    "print(f'The shape of train data is: \\n', train.shape)\n",
    "print(f'The shape of test data is: \\n', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract cabin grp and side \n",
    "def cabin_split(x):\n",
    "    ## try and exception is used to navigate through the nan values\n",
    "    try:\n",
    "        u= x.split('/')\n",
    "        return str(u[0] + u[2])\n",
    "    except AttributeError as e:\n",
    "        return x\n",
    "\n",
    "# Extract cabin grp and side\n",
    "for data in [test, train]:\n",
    "    data[\"Cabin_grp\"] = data.Cabin.apply(cabin_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fill the Cabin_grp\n",
    "for data in [train, test]:\n",
    "    data.Cabin_grp.fillna(method=\"pad\", inplace=True)\n",
    "\n",
    "# Function to Fill the Cabin from the Carbin_grp    \n",
    "def fill_cabin(data):\n",
    "    ## try and exception is used to navigate through the nan values\n",
    "    try:\n",
    "        a = data.str.split('')\n",
    "        return str(a[1] + \"/\" + str(np.random.choice(a=1500, size=1)[0])+ \"/\" + a[2])\n",
    "    except AttributeError as e:\n",
    "        return data\n",
    "\n",
    "# Fill the Cabin from the Carbin_grp\n",
    "for data in [test, train]:\n",
    "    for index, value in enumerate(list(data.Cabin.isna())):\n",
    "        if value:\n",
    "            data[\"Cabin\"].iloc[index]= data.Cabin_grp.apply(fill_cabin).iloc[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "test.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLOROTARY DATA ANALYSIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Variables : HomePlanet, CryoSleep, Destination,VIP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. HomePlanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.HomePlanet.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean \"Transported\" by HomePlanet\n",
    "\n",
    "train[['HomePlanet', 'Transported']].groupby('HomePlanet', as_index=False).mean().sort_values(by= 'Transported', ascending=False)\n",
    "\n",
    "# Europa, Mars, Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sns.barplot(x = 'HomePlanet', y ='Transported', data = train)\n",
    "plt.ylabel('Transported Probability')\n",
    "plt.title('Transported Probability by Home Planet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Destination'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean \"Transported\" by Destination\n",
    "train[[\"Destination\", \"Transported\"]].groupby('Destination', as_index=False).mean().sort_values(by=\"Transported\", ascending=False)\n",
    "\n",
    "# 55 Cancri e, PSO J318.5-22, TRAPPIST-1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sns.barplot(x=\"Destination\", y=\"Transported\", data=train)\n",
    "plt.ylabel('Transported Probability')\n",
    "plt.title('Transported Probability by Destination')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. CryoSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CryoSleep.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean \"Transpored\" by CryoSleep \n",
    "\n",
    "train[['CryoSleep', 'Transported']].groupby(\"CryoSleep\", as_index=False).mean().sort_values(by=\"Transported\", ascending=False)\n",
    "\n",
    "# True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sns.barplot(x=\"CryoSleep\", y=\"Transported\", data=train)\n",
    "plt.xlabel(\"Transported Probability\")\n",
    "plt.ylabel(\"Transported Probability by CryoSleep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VIP.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean \"Transported\" by VIP \n",
    "\n",
    "train[['VIP', 'Transported']].groupby(\"VIP\", as_index=False).mean().sort_values(by=\"Transported\", ascending=False)\n",
    "\n",
    "# False, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sns.barplot(x=\"VIP\", y=\"Transported\", data=train)\n",
    "plt.xlabel(\"Transported Probability\")\n",
    "plt.ylabel(\"Transported Probability by VIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILL MISSING TEST VALUES\n",
    "\n",
    "##### From the EDA performed earlier by Rasheed, he defined the functions below for filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Functions for Missing Values\n",
    "def fill_missing_1(data, target_column: str, cond_column1: str, cond_column2: str, cond_value1: str, cond_value2, fill):\n",
    "    common= data[target_column].isna()\n",
    "    condition= [(data[cond_column1]>= cond_value1) & (data[cond_column2]== cond_value2) & (common)]\n",
    "    fill_with= [fill]\n",
    "    data[target_column]= np.select(condition, fill_with, default= data[target_column].values)\n",
    "\n",
    "def fill_missing_2(data, target_column: str, cond_column: str, cond_value:int, fill):\n",
    "    common= data[target_column].isna()\n",
    "    cond= [(data[cond_column] <= cond_value) &(common)]\n",
    "    fill_with= [fill]\n",
    "    data[target_column]= np.select(cond, fill_with, default= data[target_column].values)\n",
    "\n",
    "def fill_missing_3(data, target_column: str, cond_column1: str, cond_column2: str, cond_value1: str, cond_value2, fill):\n",
    "    common= data[target_column].isna()\n",
    "    condition= [(data[cond_column1]== cond_value1) & (data[cond_column2]== cond_value2) & (common)]\n",
    "    fill_with= [fill]\n",
    "    data[target_column]= np.select(condition, fill_with, default= data[target_column].values)\n",
    "\n",
    "def fill_missing_4(data, target_column: str, cond_column1: str,  cond_value1: str, fill):\n",
    "    common= data[target_column].isna()\n",
    "    condition= [(data[cond_column1]== cond_value1)  & (common)]\n",
    "    fill_with= [fill]\n",
    "    data[target_column]= np.select(condition, fill_with, default= data[target_column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both train and test datas as same number of unique carbon_grp values\n",
    "\n",
    "len(train.Cabin_grp.unique()) == len(test.Cabin_grp.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill: For ages greater than 40 and cabin_grp AP,BP, BS, CS , CP HomePlanet is Europa\n",
    "# Fill: For ages greater than 40  and cabin_grp GS, GP homeplanet is Earth\n",
    "for grp in [\"AP\",\"BP\", \"BS\", \"CS\" , \"CP\", \"GS\", \"GP\"]:\n",
    "    if grp in [\"GS\", \"GP\"]:\n",
    "        fill_missing_1(train, 'HomePlanet', \"Age\", 'Cabin_grp', 40, grp, 'Earth')\n",
    "        fill_missing_1(test, 'HomePlanet', \"Age\", 'Cabin_grp', 40, grp, 'Earth')\n",
    "    else:\n",
    "        fill_missing_1(train, 'HomePlanet', \"Age\", 'Cabin_grp', 40, grp, 'Europa')\n",
    "        fill_missing_1(test, 'HomePlanet', \"Age\", 'Cabin_grp', 40, grp, 'Europa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill for Shopmall and VIP sujected to Age 12 and 20 respectively\n",
    "for data in [train, test]:\n",
    "    fill_missing_2(data, 'ShoppingMall', 'Age', 12, 0)\n",
    "    fill_missing_2(data, 'VIP', 'Age', 20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Values (Contd)\n",
    "for data in [train, test]:\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'ES', 'TRAPPIST-1e', 'Mars')\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'ES', 'PSO J318.5-22', 'Earth')\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'ES', '55 Cancri e', 'Europa')\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'ES', '55 Cancri e', 'Europa')\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'DS', '55 Cancri e', 'Europa')\n",
    "    fill_missing_3(data, 'HomePlanet', 'Cabin_grp', 'Destination', 'DP', '55 Cancri e', 'Europa')\n",
    "\n",
    "\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'AS', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'AP', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'BS', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'BP', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'CS', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'CP', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'TP', 'Europa')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'FS', 'Earth')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'GS', 'Earth')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'GP', 'Earth')\n",
    "    fill_missing_4(data, 'HomePlanet', 'Cabin_grp', 'EP', 'Earth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Values (Contd)\n",
    "for data in [train, test]:\n",
    "    data['HomePlanet']= data['HomePlanet'].fillna('Mars')\n",
    "\n",
    "    fill_missing_4(data, 'CryoSleep', 'Cabin_grp', 'BS', True)\n",
    "    fill_missing_3(data, 'CryoSleep', 'Cabin_grp', 'Destination', 'GP', '55 Cancri e', True )\n",
    "    fill_missing_3(data, 'CryoSleep', 'Cabin_grp', 'Destination', 'GS', '55 Cancri e', True )\n",
    "    ## fill the remaining missing values with False\n",
    "    data['CryoSleep'] = data['CryoSleep'].fillna(False)\n",
    "\n",
    "    ## fill VIP the misiing values with False\n",
    "    data['VIP']= data['VIP'].fillna(False)\n",
    "\n",
    "    ## fill Destination with TRAPPIST-1e\n",
    "    data['Destination']= data['Destination'].fillna('TRAPPIST-1e')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group by HomePlanet,  cabin_grp and destination then fill with median\n",
    "\n",
    "for data in [train, test]:\n",
    "    for col in ['Spa', 'VRDeck', 'ShoppingMall', 'RoomService', 'Age', 'FoodCourt']:\n",
    "        data[col] = data.groupby(['HomePlanet','Cabin_grp', 'Destination'])[col].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill the remaining Nan Values:\n",
    "\n",
    "for data in [train, test]:\n",
    "    for col in ['Spa', 'VRDeck', 'ShoppingMall', 'RoomService', 'Age', 'FoodCourt']:\n",
    "        median = data[col].median()\n",
    "        data[col].fillna(value=median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out shape of datasets\n",
    "print(f'The shape of train data is: \\n', train.shape)\n",
    "print(f'The shape of test data is: \\n', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# Function to make directory and create file\n",
    "def create_csv(filename:str, data:DataFrame):\n",
    "    directory = \"Wrangled_Data/\"\n",
    "    path = os.path.join(directory, filename)\n",
    "\n",
    "    # Make directory if directory doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if file exists and delete\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "    # Read Dataframe to csv    \n",
    "    data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(\"train_new.csv\", train)\n",
    "create_csv(\"test_new.csv\", test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "574519ca09b26aca22fcbd258939ca899adfc49e01be43018cd5e5ed113a2a51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
